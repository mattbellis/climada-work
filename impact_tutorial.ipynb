{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a304cb29-2caa-49f9-bbbf-52bf33c57753",
   "metadata": {},
   "source": [
    "https://climada-python.readthedocs.io/en/stable/tutorial/climada_engine_Impact.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d0d0d-32ce-40fd-a129-1ff13b28f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exposure from the module Litpop\n",
    "# Note that the file gpw_v4_population_count_rev11_2015_30_sec.tif must be downloaded (do not forget to unzip) if\n",
    "# you want to execute this cell on your computer. If you haven't downloaded it before, please have a look at the section \n",
    "# \"population count\" of the LitPop tutorial.\n",
    "\n",
    "import numpy as np\n",
    "import climada\n",
    "from climada.entity import LitPop\n",
    "\n",
    "import sys\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "import climada_petals\n",
    "\n",
    "import warnings # To hide the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Maybe this also?\n",
    "np.warnings = warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263e353-2672-4108-81d9-7ee536d534ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.__version__=}\")\n",
    "print(f\"python version: {sys.version_info[0]}.{sys.version_info[1]}.{sys.version_info[2]}\")\n",
    "\n",
    "print(version('climada'))\n",
    "print(version('climada_petals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d1feb-c178-4961-8f8c-190bba00ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cuba with resolution 10km and financial_mode = income group.\n",
    "exp_lp = LitPop.from_countries(countries=['CUB'], res_arcsec=300, fin_mode='income_group', reference_year=2015)\n",
    "exp_lp.check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b001df6-8a2f-4e90-bc73-3d4e01a64138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_lp.gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5e3ba-af79-4e4c-85c0-024dda9f3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed for impact calculations\n",
    "# visualize the define exposure\n",
    "exp_lp.plot_raster()\n",
    "print('\\n Raster properties exposures:', exp_lp.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e0447-3cca-4407-845b-fbb7c2b86a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.hazard import TCTracks, TropCyclone, Centroids\n",
    "\n",
    "# Load histrocial tropical cyclone tracks from ibtracs over the North Atlantic basin between 2010-2012\n",
    "ibtracks_na = TCTracks.from_ibtracs_netcdf(provider='usa', basin='NA', year_range=(2010, 2012), correct_pres=True)\n",
    "print('num tracks hist:', ibtracks_na.size)\n",
    "\n",
    "ibtracks_na.equal_timestep(0.5)  # Interpolation to make the track smooth and to allow applying calc_perturbed_trajectories\n",
    "# Add randomly generated tracks using the calc_perturbed_trajectories method (1 per historical track)\n",
    "ibtracks_na.calc_perturbed_trajectories(nb_synth_tracks=1)\n",
    "print('num tracks hist+syn:', ibtracks_na.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d81ee-3794-4c1d-8f0f-7f72857ddaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed for calculations\n",
    "# visualize tracks\n",
    "ax = ibtracks_na.plot()\n",
    "ax.get_legend()._loc = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae76f05-394e-49c0-8a85-cc2940a32b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the centroids from the exposures position\n",
    "lat = exp_lp.gdf['latitude'].values\n",
    "lon = exp_lp.gdf['longitude'].values\n",
    "centrs = Centroids.from_lat_lon(lat, lon)\n",
    "centrs.check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fa36c-de47-4b34-aca2-5f86906b8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tracks, compute the windspeed at the location of the centroids\n",
    "tc = TropCyclone.from_tracks(ibtracks_na, centroids=centrs)\n",
    "tc.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7311f6-17ae-456d-b64e-90038723a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.entity import ImpactFuncSet, ImpfTropCyclone\n",
    "# impact function TC\n",
    "impf_tc = ImpfTropCyclone.from_emanuel_usa()\n",
    "\n",
    "# add the impact function to an Impact function set\n",
    "impf_set = ImpactFuncSet([impf_tc])\n",
    "impf_set.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2337cd-227f-4862-abf2-87a4d43c0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hazard type and hazard id\n",
    "[haz_type] = impf_set.get_hazard_types()\n",
    "[haz_id] = impf_set.get_ids()[haz_type]\n",
    "print(f\"hazard type: {haz_type}, hazard id: {haz_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0a456-0b9f-421e-84b8-95bdfbdb3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exposures: rename column and assign id\n",
    "exp_lp.gdf.rename(columns={\"impf_\": \"impf_\" + haz_type}, inplace=True)\n",
    "exp_lp.gdf['impf_' + haz_type] = haz_id\n",
    "exp_lp.check()\n",
    "exp_lp.gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d854537-b5fb-4430-bbe1-be8cc2cfbf92",
   "metadata": {},
   "source": [
    "This next cell is generating an error. Discussed here. \n",
    "\n",
    "https://github.com/CLIMADA-project/climada_python/issues/796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4ca59-3191-4352-8b64-a1911cb98f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute impact\n",
    "from climada.engine import ImpactCalc\n",
    "imp = ImpactCalc(exp_lp, impf_set, tc).impact(save_mat=False)  # Do not save the results geographically resolved (only aggregate values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435c065-72f0-4c0b-a563-123b8b061ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lp.gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022fb2d-9f2c-4fb5-b521-f30d95e67b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Aggregated average annual impact: {round(imp.aai_agg,0)} $\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13f45e-ce87-4a70-ab27-7dda0d8e0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.plot_hexbin_eai_exposure(buffer=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0570c-0d5d-47b2-a1f2-bb6ab2f583e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute exceedance frequency curve\n",
    "freq_curve = imp.calc_freq_curve()\n",
    "freq_curve.plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0a960-3d7a-40b3-9427-8a4319c3b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "\n",
    "#set a harvest date\n",
    "harvest_DOY=290 #17 October\n",
    "\n",
    "#loop over all events an check if they happened before or after harvest\n",
    "event_ids_post_harvest=[]\n",
    "event_ids_pre_harvest=[]\n",
    "for event_id in tc.event_id:\n",
    "            event_date = tc.date[np.where(tc.event_id==event_id)[0][0]]\n",
    "            day_of_year = event_date - date(datetime.fromordinal(event_date).year, 1, 1).toordinal() + 1\n",
    "            \n",
    "            if day_of_year > harvest_DOY:\n",
    "                event_ids_post_harvest.append(event_id)\n",
    "            else:\n",
    "                event_ids_pre_harvest.append(event_id)\n",
    "\n",
    "tc_post_harvest=tc.select(event_id=event_ids_post_harvest)\n",
    "tc_pre_harvest=tc.select(event_id=event_ids_pre_harvest)\n",
    "#print('pre-harvest:', tc_pre_harvest.event_name)\n",
    "#print('post-harvest:', tc_post_harvest.event_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6387914-c49a-4b0c-9cc6-d9cca33846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.engine import Impact\n",
    "# impact function TC\n",
    "impf_tc = ImpfTropCyclone.from_emanuel_usa()\n",
    "# impact function TC after harvest is by factor 0.5 smaller\n",
    "impf_tc_posth = ImpfTropCyclone.from_emanuel_usa()\n",
    "impf_tc_posth.mdd = impf_tc.mdd*0.1\n",
    "# add the impact function to an Impact function set\n",
    "impf_set = ImpactFuncSet([impf_tc])\n",
    "impf_set_posth = ImpactFuncSet([impf_tc_posth])\n",
    "impf_set.check()\n",
    "impf_set_posth.check()\n",
    "\n",
    "#plot\n",
    "impf_set.plot()\n",
    "impf_set_posth.plot()\n",
    "\n",
    "# Compute impacts\n",
    "imp_preh = ImpactCalc(exp_lp, impf_set, tc_pre_harvest).impact(save_mat=True)\n",
    "imp_posth = ImpactCalc(exp_lp, impf_set_posth, tc_post_harvest).impact(save_mat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a92b9d-9351-403b-8cd4-c26d070acc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate impacts again\n",
    "imp_tot = Impact.concat([imp_preh,imp_posth])\n",
    "\n",
    "#plot result\n",
    "import matplotlib.pyplot as plt\n",
    "ax=imp_preh.plot_hexbin_eai_exposure(gridsize=100,adapt_fontsize=False)\n",
    "ax.set_title('Expected annual impact: Pre-Harvest')\n",
    "ax=imp_posth.plot_hexbin_eai_exposure(gridsize=100,adapt_fontsize=False)\n",
    "ax.set_title('Expected annual impact: Post-Harvest')\n",
    "ax=imp_tot.plot_hexbin_eai_exposure(gridsize=100,adapt_fontsize=False)\n",
    "ax.set_title('Expected annual impact: Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cacc9b-d4a2-442d-9b47-98e49363a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: POINT EXPOSURES WITH POINT HAZARD\n",
    "import numpy as np\n",
    "from climada.entity import Exposures, ImpactFuncSet, IFTropCyclone\n",
    "from climada.hazard import Centroids, TCTracks, TropCyclone\n",
    "from climada.engine import ImpactCalc\n",
    "\n",
    "# Set Exposures in points\n",
    "exp_pnt = Exposures(crs='epsg:4326') #set coordinate system\n",
    "exp_pnt.gdf['latitude'] = np.array([21.899326, 21.960728, 22.220574, 22.298390, 21.787977, 21.787977, 21.981732])\n",
    "exp_pnt.gdf['longitude'] = np.array([88.307422, 88.565362, 88.378337, 87.806356, 88.348835, 88.348835, 89.246521])\n",
    "exp_pnt.gdf['value'] = np.array([1.0e5, 1.2e5, 1.1e5, 1.1e5, 2.0e5, 2.5e5, 0.5e5])\n",
    "exp_pnt.check()\n",
    "exp_pnt.plot_scatter(buffer=0.05)\n",
    "\n",
    "# Set Hazard in Exposures points\n",
    "# set centroids from exposures coordinates\n",
    "centr_pnt = Centroids.from_lat_lon(exp_pnt.gdf.latitude.values, exp_pnt.gdf.longitude.values, exp_pnt.crs)\n",
    "# compute Hazard in that centroids\n",
    "tr_pnt = TCTracks.from_ibtracs_netcdf(storm_id='2007314N10093')\n",
    "tc_pnt = TropCyclone.from_tracks(tr_pnt, centroids=centr_pnt)\n",
    "tc_pnt.check()\n",
    "ax_pnt = tc_pnt.centroids.plot(c=np.array(tc_pnt.intensity[0,:].todense()).squeeze()) # plot intensity per point\n",
    "ax_pnt.get_figure().colorbar(ax_pnt.collections[0], fraction=0.0175, pad=0.02).set_label('Intensity (m/s)') # add colorbar\n",
    "\n",
    "# Set impact function\n",
    "impf_tc = ImpfTropCyclone.from_emanuel_usa()\n",
    "impf_pnt = ImpactFuncSet([impf_tc])\n",
    "impf_pnt.check()\n",
    "\n",
    "# Get the hazard type and hazard id\n",
    "[haz_type] = impf_set.get_hazard_types()\n",
    "[haz_id] = impf_set.get_ids()[haz_type]\n",
    "# Exposures: rename column and assign id\n",
    "exp_lp.gdf.rename(columns={\"impf_\": \"impf_\" + haz_type}, inplace=True)\n",
    "exp_lp.gdf['impf_' + haz_type] = haz_id\n",
    "exp_lp.gdf.head()\n",
    "\n",
    "# Compute Impact\n",
    "imp_pnt = ImpactCalc(exp_pnt, impf_pnt, tc_pnt).impact()\n",
    "# nearest neighbor of exposures to centroids gives identity\n",
    "print('Nearest neighbor hazard.centroids indexes for each exposure:', exp_pnt.gdf.centr_TC.values)\n",
    "imp_pnt.plot_scatter_eai_exposure(ignore_zero=False, buffer=0.05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71814363-8707-412e-b975-626bf8c6c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import Resampling\n",
    "from climada.entity import LitPop, ImpactFuncSet, ImpactFunc\n",
    "from climada.hazard import Hazard\n",
    "from climada.engine import Impact\n",
    "from climada.util.constants import HAZ_DEMO_FL\n",
    "\n",
    "# Exposures belonging to a raster (the raser information is contained in the meta attribute)\n",
    "exp_ras = LitPop.from_countries(countries=['VEN'], res_arcsec=300, fin_mode='income_group')\n",
    "exp_ras.gdf.reset_index()\n",
    "exp_ras.check()\n",
    "exp_ras.plot_raster()\n",
    "print('\\n Raster properties exposures:', exp_ras.meta)\n",
    "\n",
    "# Initialize hazard object with haz_type = 'FL' (for Flood)\n",
    "hazard_type='FL'\n",
    "# Load a previously generated (either with CLIMADA or other means) hazard\n",
    "# from file (HAZ_DEMO_FL) and resample the hazard raster to the exposures' ones\n",
    "# Hint: check how other resampling methods affect to final impact\n",
    "haz_ras = Hazard.from_raster([HAZ_DEMO_FL], haz_type=hazard_type, dst_crs=exp_ras.meta['crs'], transform=exp_ras.meta['transform'],\n",
    "                             width=exp_ras.meta['width'], height=exp_ras.meta['height'],\n",
    "                             resampling=Resampling.nearest)\n",
    "haz_ras.intensity[haz_ras.intensity==-9999] = 0 # correct no data values\n",
    "haz_ras.check()\n",
    "haz_ras.plot_intensity(1)\n",
    "print('Raster properties centroids:', haz_ras.centroids.meta)\n",
    "\n",
    "# Set dummy impact function\n",
    "intensity = np.linspace(0, 10, 100)\n",
    "mdd = np.linspace(0, 10, 100)\n",
    "paa = np.ones(intensity.size)\n",
    "impf_dum = ImpactFunc(hazard_type, haz_id, intensity, mdd, paa, \"m\", \"dummy\")\n",
    "# Add the impact function to the impact function set\n",
    "impf_ras = ImpactFuncSet([impf_dum])\n",
    "impf_ras.check()\n",
    "\n",
    "# Exposures: rename column and assign id\n",
    "exp_lp.gdf.rename(columns={\"impf_\": \"impf_\" + hazard_type}, inplace=True)\n",
    "exp_lp.gdf['impf_' + haz_type] = haz_id\n",
    "exp_lp.gdf.head()\n",
    "\n",
    "# Compute impact\n",
    "imp_ras = ImpactCalc(exp_ras, impf_ras, haz_ras).impact(save_mat=False)\n",
    "# nearest neighbor of exposures to centroids is not identity because litpop does not contain data outside the country polygon\n",
    "print('\\n Nearest neighbor hazard.centroids indexes for each exposure:', exp_ras.gdf.centr_FL.values)\n",
    "imp_ras.plot_raster_eai_exposure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9de0c-4fe3-4570-a479-1bd865910507",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e7014-3957-4a64-9096-e8f34d4864b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_pnt.plot_basemap_eai_exposure(buffer=5000);\n",
    "imp_ras.plot_basemap_eai_exposure(buffer=5000);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e253494-5347-4ea4-91aa-c2dbab3db877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.entity import add_sea\n",
    "from climada_petals.entity import BlackMarble\n",
    "\n",
    "exp_video = BlackMarble()\n",
    "exp_video.set_countries(['Cuba'], 2016, res_km=2.5)\n",
    "exp_video.check()\n",
    "\n",
    "# impact function\n",
    "impf_def = ImpfTropCyclone.from_emanuel_usa()\n",
    "impfs_video = ImpactFuncSet([impf_def])\n",
    "impfs_video.check()\n",
    "\n",
    "# compute sequence of hazards using TropCyclone video_intensity method\n",
    "exp_sea = add_sea(exp_video, (100, 5))\n",
    "centr_video = Centroids.from_lat_lon(exp_sea.gdf.latitude.values, exp_sea.gdf.longitude.values)\n",
    "centr_video.check()\n",
    "\n",
    "track_name = '2017242N16333'\n",
    "tr_irma = TCTracks.from_ibtracs_netcdf(provider='usa', storm_id=track_name) # IRMA 2017\n",
    "\n",
    "tc_video = TropCyclone()\n",
    "tc_list, _ = tc_video.video_intensity(track_name, tr_irma, centr_video) # empty file name to not to write the video\n",
    "\n",
    "# generate video of impacts\n",
    "file_name='./results/irma_imp_fl.gif'\n",
    "imp_video = Impact()\n",
    "imp_list = imp_video.video_direct_impact(exp_video, impfs_video, tc_list, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0223be-6046-436d-80a3-9daeae29af49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
